# Baseline Random Forest Model for Gestational Diabetes Prediction

```{r}
# Load required libraries
library(randomForest)
library(caret)
library(pROC)
```
```{r}
# Load the data
data <- read.csv("/Users/arnenyecknyeck/Desktop/Statistical-Inference-Package/completed_data_rf.csv")
# Feature columns
feature_cols <- c("Pregnancies", "Glucose", "BloodPressure", "SkinThickness", 
                  "Insulin", "BMI", "Pedigree", "Age")

```
```{r}
# Check class distribution
cat("Class distribution:\n")
table(data$Diagnosis)
```

## DATA PREPARATION

```{r}
# Prepare data for modeling (no preprocessing - baseline approach)
set.seed(123)

# Simple train-test split (70-30)
train_index <- createDataPartition(data$Diagnosis, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]

# Convert target to factor for Random Forest
train_data$Diagnosis <- factor(train_data$Diagnosis, levels = c(0, 1), labels = c("No", "Yes"))
test_data$Diagnosis <- factor(test_data$Diagnosis, levels = c(0, 1), labels = c("No", "Yes"))

# Check class proportions
cat("\nTraining set proportions:\n")
prop.table(table(train_data$Diagnosis))
cat("\nTest set proportions:\n")
prop.table(table(test_data$Diagnosis))


```

## BASELINE RANDOM FOREST MODEL

```{r}
# Fit Random Forest with default parameters (baseline model)
set.seed(123)
rf_model <- randomForest(
  x = train_data[feature_cols],
  y = train_data$Diagnosis,
  ntree = 500,                    # Standard number of trees
  importance = TRUE,              # Calculate feature importance
  proximity = FALSE,              # Don't calculate proximity matrix
  do.trace = FALSE               # No verbose output
)

cat("\n=== Baseline Random Forest Model ===\n")
print(rf_model)

```

##  MODEL EVALUATION

```{r}
# Predictions on test set
test_pred_class <- predict(rf_model, newdata = test_data[feature_cols])
test_pred_prob <- predict(rf_model, newdata = test_data[feature_cols], type = "prob")[, "Yes"]

# Confusion matrix
conf_mat <- confusionMatrix(test_pred_class, test_data$Diagnosis, positive = "Yes")
print(conf_mat)

# Calculate additional metrics
TP <- conf_mat$table[2, 2]
FP <- conf_mat$table[2, 1]
FN <- conf_mat$table[1, 2]

precision <- if ((TP + FP) == 0) NA else TP / (TP + FP)
recall <- if ((TP + FN) == 0) NA else TP / (TP + FN)
f1 <- if (is.na(precision) | is.na(recall) | (precision + recall == 0)) NA else 2 * (precision * recall) / (precision + recall)
f2 <- if (is.na(precision) | is.na(recall) | ((4 * precision) + recall == 0)) NA else (5 * precision * recall) / ((4 * precision) + recall)

# ROC AUC
roc_val <- tryCatch({
  pROC::roc(test_data$Diagnosis, test_pred_prob, quiet = TRUE)$auc
}, error = function(e) NA)

cat("\n=== Baseline Random Forest Performance ===\n")
cat("Test Set Metrics:\n")
cat("Accuracy:", round(conf_mat$overall["Accuracy"], 4), "\n")
cat("Sensitivity:", round(conf_mat$byClass["Sensitivity"], 4), "\n")
cat("Specificity:", round(conf_mat$byClass["Specificity"], 4), "\n")
cat("Precision:", round(precision, 4), "\n")
cat("F1 Score:", round(f1, 4), "\n")
cat("F2 Score:", round(f2, 4), "\n")
cat("ROC AUC:", round(roc_val, 4), "\n")
```

### FEATURE IMPORTANCE

```{r}

# Extract feature importance
importance_scores <- importance(rf_model)
importance_df <- data.frame(
  Feature = rownames(importance_scores),
  MeanDecreaseAccuracy = importance_scores[, "MeanDecreaseAccuracy"],
  MeanDecreaseGini = importance_scores[, "MeanDecreaseGini"]
)

# Sort by Mean Decrease in Accuracy (most interpretable measure)
importance_df <- importance_df[order(importance_df$MeanDecreaseAccuracy, decreasing = TRUE), ]

cat("\n=== Feature Importance (Baseline Random Forest) ===\n")
cat("Ranking by Mean Decrease in Accuracy:\n")
for(i in 1:nrow(importance_df)) {
  cat(sprintf("%d. %s: %.4f\n", 
              i, 
              importance_df$Feature[i], 
              importance_df$MeanDecreaseAccuracy[i]))
}

```


### BASELINE MODEL SUMMARY

```{r}
cat("\n=== Baseline Random Forest Summary ===\n")
cat("Model Type: Default Random Forest (Baseline)\n")
cat("Number of Trees:", rf_model$ntree, "\n")
cat("Variables per Split (mtry):", rf_model$mtry, "\n")
cat("Features Used: All", length(feature_cols), "features\n")
cat("Preprocessing: None (raw data)\n")
cat("\nPerformance Summary:\n")
cat("- Test AUC:", round(roc_val, 4), "\n")
cat("- Balanced Accuracy:", round((conf_mat$byClass["Sensitivity"] + conf_mat$byClass["Specificity"])/2, 4), "\n")

```


